{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IslamiTP/Intro-to-LLM-Homework-2/blob/main/run_ollama_in_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0MJe6AusVtI"
      },
      "source": [
        "## Run Ollama in Colab\n",
        "\n",
        "### Code to initialize llama using Unsloth was retrieved from\n",
        "\n",
        "https://colab.research.google.com/drive/1T5-zKWM_5OD21QHwXHiV9ixTRR7k3iB9?usp=sharing#scrollTo=2eSvM9zX_2d3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install unsloth"
      ],
      "metadata": {
        "id": "3KJQQP3ZvVI5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = False # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 2x faster\n",
        "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # 4bit for 405b!\n",
        "    \"unsloth/Mistral-Small-Instruct-2409\",     # Mistral 22b 2x faster!\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
        "\n",
        "    \"unsloth/Llama-3.2-1B-bnb-4bit\",           # NEW! Llama 3.2 models\n",
        "    \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Llama-3.2-3B-bnb-4bit\",\n",
        "    \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n",
        "\n",
        "    \"unsloth/Llama-3.3-70B-Instruct-bnb-4bit\" # NEW! Llama 3.3 70B!\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Llama-3.2-3B-Instruct\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-kJWXK4vYy8",
        "outputId": "efcf2b27-9709-4cf3-8ed2-eb6722975fed"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.3.18: Fast Llama patching. Transformers: 4.49.0.\n",
            "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 1, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ],
      "metadata": {
        "id": "gzxZE8YozcGW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3.2\",\n",
        ")\n",
        "\n",
        "def formatting_train_prompts(examples):\n",
        "    convos = examples[\"conversations\"]\n",
        "    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n",
        "    return { \"text\" : texts, }\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],  # Use only text\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=2048,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the full dataset\n",
        "full_dataset = load_dataset(\"mlabonne/FineTome-100k\", split=\"train\")\n",
        "\n",
        "# Split the dataset into training and testing sets (e.g., 80% train, 20% test)\n",
        "split_datasets = full_dataset.train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "# Access the train and test splits\n",
        "train_dataset = split_datasets['train']\n",
        "test_dataset = split_datasets['test']\n",
        "\n",
        "print(f\"Train dataset: {train_dataset}\")\n",
        "print(f\"Test dataset: {test_dataset}\")"
      ],
      "metadata": {
        "id": "WHB254cnJB2t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e5d3214-3ae4-48e5-d81e-68ac63d48861"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset: Dataset({\n",
            "    features: ['conversations', 'source', 'score'],\n",
            "    num_rows: 80000\n",
            "})\n",
            "Test dataset: Dataset({\n",
            "    features: ['conversations', 'source', 'score'],\n",
            "    num_rows: 20000\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth.chat_templates import standardize_sharegpt\n",
        "train_dataset = standardize_sharegpt(train_dataset)\n",
        "train_dataset = train_dataset.map(formatting_train_prompts, batched = True,)\n",
        "test_dataset = standardize_sharegpt(test_dataset)\n",
        "test_dataset = test_dataset.map(formatting_train_prompts, batched=True)\n",
        "tokenized_datasets = test_dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "L5o4EfODWYmy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Performance on 5 different categories outlined in question #1 before training"
      ],
      "metadata": {
        "id": "Ai0WvoLUIdyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "import torch\n",
        "\n",
        "# Assuming tokenizer and model are already loaded\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template=\"llama-3.2\",\n",
        ")\n",
        "\n",
        "# Define a list of messages (each entry follows the chat template format)\n",
        "\n",
        "message_list = [\n",
        "    [# Text Summarization\n",
        "     {\"role\": \"user\", \"content\": \"Antibiotics are a type of medication used to treat bacterial infections. They work by either killing the bacteria or preventing them from reproducing, allowing the body’s immune system to fight off the infection. Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions, or sometimes administered intravenously. They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance.\\n\\n\"},\n",
        "     {\"role\": \"user\", \"content\": \"Explain the above in one sentence.\\n\\n\"}],\n",
        "\n",
        "    [# Question Answering\n",
        "     {\"role\": \"user\", \"content\": \"Answer the question based on the context below. Keep the answer short and concise. Respond 'Unsure about answer' if not sure about the answer.\\n\\n\"},\n",
        "     {\"role\": \"user\", \"content\": \"Context: Teplizumab traces its roots to a New Jersey drug company called Ortho Pharmaceutical. There, scientists generated an early version of the antibody, dubbed OKT3. Originally sourced from mice, the molecule was able to bind to the surface of T cells and limit their cell-killing potential. In 1986, it was approved to help prevent organ rejection after kidney transplants, making it the first therapeutic antibody allowed for human use.\\n\\n\"},\n",
        "     {\"role\": \"user\", \"content\": \"Question: What was OKT3 originally sourced from?\\n\\n\"}],\n",
        "\n",
        "    [# Text Classification\n",
        "     {\"role\": \"user\", \"content\": \"Classify the text into neutral, negative or positive.\\n\\n\"},\n",
        "     {\"role\": \"user\", \"content\": \"Text: I think the food was okay.\\n\\n\"}],\n",
        "\n",
        "    [# Role Playing\n",
        "     {\"role\": \"system\", \"content\": \"The following is a conversation with an AI research assistant. The assistant tone is technical and scientific.\\n\\n\"},\n",
        "     {\"role\": \"user\", \"content\": \"Hello, who are you?\\n\\n\"},\n",
        "     {\"role\": \"assistant\", \"content\": \"Greeting! I am an AI research assistant. How can I help you today?\\n\\n\"},\n",
        "     {\"role\": \"user\", \"content\": \"Can you tell me about the creation of blackholes?\\n\\n\"}],\n",
        "\n",
        "    [# Reasoning\n",
        "     {\"role\": \"system\", \"content\": \"The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\\n\\n\"},\n",
        "     {\"role\": \"user\", \"content\": \"Solve by breaking the problem into steps. First, identify the odd numbers, add them, and indicate whether the result is odd or even.\\n\\n\"}]\n",
        "]\n",
        "\n",
        "# Store results\n",
        "generated_outputs = []\n",
        "\n",
        "# Iterate through message list and generate responses\n",
        "for messages in message_list:\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=True,  # Required for generation\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # Run inference without gradient tracking\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids=inputs,\n",
        "            max_new_tokens=2048,\n",
        "            use_cache=True,\n",
        "            temperature=1.5,\n",
        "            min_p=0.1\n",
        "        )\n",
        "\n",
        "    # Decode and store the output\n",
        "    output_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "    generated_outputs.append(output_text)\n",
        "\n",
        "prompt_types = [\"Text Summarization\", \"Question Answering\", \"Text Classification\", \"Role Playing\", \"Reasoning\"]\n",
        "\n",
        "# Print all generated responses\n",
        "for response, prompt_type in zip(generated_outputs, prompt_types):\n",
        "    print(f\"Prompt Type: {prompt_type}\\n\\n\")\n",
        "\n",
        "    print(f\"Response: {response}\\n\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y990-s8batG",
        "outputId": "39a9abee-bff5-4752-ddc3-622b4c1d17f8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt Type: Text Summarization\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "user\n",
            "\n",
            "Antibiotics are a type of medication used to treat bacterial infections. They work by either killing the bacteria or preventing them from reproducing, allowing the body’s immune system to fight off the infection. Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions, or sometimes administered intravenously. They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance.\n",
            "\n",
            "user\n",
            "\n",
            "Explain the above in one sentence.\n",
            "\n",
            "assistant\n",
            "\n",
            "Antibiotics are a type of medication that kill or prevent bacteria from reproducing, allowing the body's immune system to fight off infections, but they are ineffective against viral infections and can lead to antibiotic resistance if used improperly.\n",
            "\n",
            "\n",
            "\n",
            "Prompt Type: Question Answering\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "user\n",
            "\n",
            "Answer the question based on the context below. Keep the answer short and concise. Respond 'Unsure about answer' if not sure about the answer.\n",
            "\n",
            "user\n",
            "\n",
            "Context: Teplizumab traces its roots to a New Jersey drug company called Ortho Pharmaceutical. There, scientists generated an early version of the antibody, dubbed OKT3. Originally sourced from mice, the molecule was able to bind to the surface of T cells and limit their cell-killing potential. In 1986, it was approved to help prevent organ rejection after kidney transplants, making it the first therapeutic antibody allowed for human use.\n",
            "\n",
            "user\n",
            "\n",
            "Question: What was OKT3 originally sourced from?\n",
            "\n",
            "assistant\n",
            "\n",
            "Mice.\n",
            "\n",
            "\n",
            "\n",
            "Prompt Type: Text Classification\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "user\n",
            "\n",
            "Classify the text into neutral, negative or positive.\n",
            "\n",
            "user\n",
            "\n",
            "Text: I think the food was okay.\n",
            "\n",
            "assistant\n",
            "\n",
            "I would classify the text as neutral. The statement \"I think the food was okay\" neither expresses strong enthusiasm nor criticism, but rather a mediocre assessment of the food.\n",
            "\n",
            "\n",
            "\n",
            "Prompt Type: Role Playing\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "The following is a conversation with an AI research assistant. The assistant tone is technical and scientific.\n",
            "\n",
            "user\n",
            "\n",
            "Hello, who are you?\n",
            "\n",
            "assistant\n",
            "\n",
            "Greeting! I am an AI research assistant. How can I help you today?\n",
            "\n",
            "user\n",
            "\n",
            "Can you tell me about the creation of blackholes?\n",
            "\n",
            "assistant\n",
            "\n",
            "The formation of black holes is a complex and multifaceted process, grounded in astrophysical and gravitational theories.\n",
            "\n",
            "According to general relativity, black holes are regions of spacetime where the curvature is so intense that not even light can escape, effectively forming a boundary known as the event horizon.\n",
            "\n",
            "The formation of a black hole typically occurs when a massive star undergoes a catastrophic collapse, resulting in a singularity, where the gravitational field becomes infinite. This process can occur through various means, including:\n",
            "\n",
            "1. **Stellar collapse**: When a massive star exhausts its fuel and dies, its core collapses, causing a massive release of gravitational energy and the formation of a black hole.\n",
            "\n",
            "2. **Mergers**: When two massive compact objects, such as neutron stars or supermassive black holes, merge, they can produce an enormous amount of energy, potentially forming a new, more massive black hole.\n",
            "\n",
            "3. **Primordial black holes**: Hypothetical black holes formed in the early universe during the rapid expansion and cooling process, which could have seeded the formation of the cosmic structures we see today.\n",
            "\n",
            "Once a black hole is formed, it will grow and accrete matter from its surroundings, potentially forming a supermassive black hole at the center of a galaxy.\n",
            "\n",
            "I hope this information helps! Are there any specific aspects of black hole formation you'd like me to elaborate on?\n",
            "\n",
            "\n",
            "\n",
            "Prompt Type: Reasoning\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
            "\n",
            "user\n",
            "\n",
            "Solve by breaking the problem into steps. First, identify the odd numbers, add them, and indicate whether the result is odd or even.\n",
            "\n",
            "assistant\n",
            "\n",
            "Let's break the problem down into steps.\n",
            "\n",
            "Step 1: Identify the odd numbers in the given list.\n",
            "The odd numbers in the list are: 15, 5, 13, 7, 1.\n",
            "\n",
            "Step 2: Add the odd numbers.\n",
            "15 + 5 = 20\n",
            "20 + 13 = 33\n",
            "33 + 7 = 40\n",
            "40 + 1 = 41\n",
            "\n",
            "The sum of the odd numbers is: 41\n",
            "\n",
            "Step 3: Determine whether the result (41) is odd or even.\n",
            "The result, 41, is odd.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model performance on the representative dataset before training"
      ],
      "metadata": {
        "id": "Ez37R6nEnp5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages_list = [[{\"role\": conv[\"role\"], \"content\": conv[\"content\"] + \"\\n\\n\"} for conv in message] for message in test_dataset[\"conversations\"][:5]] # test the first 5 samples of the representative dataset that will be trained\n",
        "\n",
        "# Store results\n",
        "generated_outputs = []\n",
        "\n",
        "# Iterate through message list and generate responses\n",
        "for messages in messages_list:\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=True,  # Required for generation\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # Run inference without gradient tracking\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids=inputs,\n",
        "            max_new_tokens=2048,\n",
        "            use_cache=True,\n",
        "            temperature=1.5,\n",
        "            min_p=0.1\n",
        "        )\n",
        "\n",
        "    # Decode and store the output\n",
        "    output_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "    generated_outputs.append(output_text)\n",
        "\n",
        "for response in generated_outputs:\n",
        "    print(f\"Response: {response}\\n\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYlBbXFZnpbN",
        "outputId": "085dc32b-5d28-4b7e-efa1-7c517eaf7967"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "user\n",
            "\n",
            "Give three types of computer graphics.\n",
            "\n",
            "assistant\n",
            "\n",
            "1. Raster Graphics: These are also called bitmap graphics and are composed of pixels arranged in a grid. Each pixel can have a different color and shade. Raster graphics excel at representing photographic images and digital painting.\n",
            "\n",
            "2. Vector Graphics: These graphics are constructed using mathematical formulas representing geometric shapes like lines, curves, and polygons. They are resolution-independent, meaning they can be scaled up or down in size without losing quality. Vector graphics are commonly used for logos, icons, typography and illustrations.\n",
            "\n",
            "3. 3D Graphics: These graphics are used to create three-dimensional digital representations of objects. 3D graphics use techniques like modeling, rendering, and shading to simulate depth and surface properties. These graphics are used in animation, video games, architecture, engineering, and virtual reality.\n",
            "\n",
            "assistant\n",
            "\n",
            "These three types of computer graphics work together to create the diverse range of visual content that we see in digital media, including websites, video games, films, and more.\n",
            "\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "user\n",
            "\n",
            "Write Python code to solve the task:\n",
            "Let S be the concatenation of 10^{10} copies of the string 110. (For reference, the concatenation of 3 copies of 110 is 110110110.)\n",
            "We have a string T of length N.\n",
            "Find the number of times T occurs in S as a contiguous substring.\n",
            "\n",
            "-----Constraints-----\n",
            " - 1 \\leq N \\leq 2 \\times 10^5\n",
            " - T is a string of length N consisting of 0 and 1.\n",
            "\n",
            "-----Input-----\n",
            "Input is given from Standard Input in the following format:\n",
            "N\n",
            "T\n",
            "\n",
            "-----Output-----\n",
            "Print the number of times T occurs in S as a contiguous substring.\n",
            "\n",
            "-----Sample Input-----\n",
            "4\n",
            "1011\n",
            "\n",
            "-----Sample Output-----\n",
            "9999999999\n",
            "\n",
            "S is so long, so let us instead count the number of times 1011 occurs in the concatenation of 3 copies of 110, that is, 110110110. We can see it occurs twice:\n",
            " - 1 1011 0110\n",
            " - 1101 1011 0\n",
            "\n",
            "assistant\n",
            "\n",
            "Step 1:  The problem requires finding the number of times a string T occurs as a contiguous substring in a very long string S.\n",
            "Step 2:  Since we are given the pattern and the length of T, we can use the occurrences of T in a shorter pattern to simplify the counting.\n",
            "Step 3:  We can identify edge cases by checking if T contains '00' or '111' and handle them accordingly.\n",
            "Step 4:  For the cases where '00', '111', or '010' is present in T, the number of occurrences is 0.\n",
            "Step 5:  If the last character of T is '1', then the number of occurrences is 10^10 - the count of '0' in T. Otherwise, it's 10^10 - the count of '0' in T plus 1.\n",
            "```python\n",
            "# Step 6:  Initialize the length of the input string.\n",
            "n = int(input())\n",
            "# Step 7:  Read the input string.\n",
            "t = input()\n",
            "# Step 8:  Check if the input string corresponds to specific cases and print the result accordingly.\n",
            "if t == '1':\n",
            "    print(10 ** 10 * 2)\n",
            "elif t == '11':\n",
            "    print(10 ** 10)\n",
            "elif '00' in t or '111' in t or '010' in t:\n",
            "    print(0)\n",
            "else:\n",
            "    # Step 9:  Count the occurrences of '0' in the input string.\n",
            "    \n",
            "    a = t.count('0')\n",
            "    # Step 10:  Print the number of times T occurs in S as a contiguous substring based on specific conditions.\n",
            "    \n",
            "    if t[-1] == '1':\n",
            "        print(10 ** 10 - a)\n",
            "    else:\n",
            "        print(10 ** 10 - a + 1)\n",
            "\n",
            "```\n",
            "\n",
            "assistant\n",
            "\n",
            "The solution you've provided is clear and well-structured. It effectively addresses the task by breaking it down into smaller, manageable parts, and includes edge cases to handle potential inputs.\n",
            "\n",
            "However, I would suggest a few improvements to make the code even more efficient and user-friendly:\n",
            "\n",
            "1.  Input Validation: While the code checks for certain edge cases, it doesn't validate if the input string is a string (which could potentially lead to an error). You can add a simple `if not isinstance(t, str)` check to ensure that `t` is indeed a string.\n",
            "\n",
            "2.  Documentation: It would be helpful to include a docstring to describe what the function does, its parameters, and return values. This would improve code readability and maintainability.\n",
            "\n",
            "3.  Variable Naming: Some variable names like `n` and `t` could be more descriptive. For example, `num_length` for `n` and `target_string` for `t`.\n",
            "\n",
            "4.  Comments: While the code includes comments, it's a good practice to use Python's built-in docstring style comments (with triple quotes) to document your code.\n",
            "\n",
            "Here is an updated version of your solution that includes these improvements:\n",
            "\n",
            "```python\n",
            "def count_target_substrings(num_length, target_string):\n",
            "    \"\"\"\n",
            "    Counts the number of times target_string occurs in S as a contiguous substring.\n",
            "\n",
            "    Args:\n",
            "        num_length (int): The number of occurrences of the target string.\n",
            "        target_string (str): The target string.\n",
            "\n",
            "    Returns:\n",
            "        int: The number of times target_string occurs in S as a contiguous substring.\n",
            "\n",
            "    Raises:\n",
            "        TypeError: If either num_length or target_string is not of type int or str, respectively.\n",
            "    \"\"\"\n",
            "\n",
            "    if not isinstance(num_length, int):\n",
            "        raise TypeError(\"num_length must be of type int\")\n",
            "    if not isinstance(target_string, str):\n",
            "        raise TypeError(\"target_string must be of type str\")\n",
            "\n",
            "    # Check for specific edge cases\n",
            "    if '00' in target_string or '111' in target_string or '010' in target_string:\n",
            "        return 0\n",
            "\n",
            "    # Count the occurrences of '0' in target_string\n",
            "    a = target_string.count('0')\n",
            "    if target_string[-1] == '1':\n",
            "        return 10 ** 10 * num_length - a\n",
            "    else:\n",
            "        return 10 ** 10 * num_length - a + 1\n",
            "```\n",
            "\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "user\n",
            "\n",
            "Can you provide information on the most effective methods for teaching language to young children?\n",
            "\n",
            "assistant\n",
            "\n",
            "As an AI language model, I can provide you with some information on effective methods of teaching language to young children:\n",
            "\n",
            "1. Immersion: Immersing children in the language they are trying to learn is an effective way to teach them a language. Children can be taught through games, songs, books, stories, and other fun activities that make learning an enjoyable experience.\n",
            "\n",
            "2. Repetition: Repetition is essential for children to learn a language. Repetitive words, phrases, and sentences help children remember and understand the language better.\n",
            "\n",
            "3. Total physical response (TPR): Total physical response (TPR) is a method of teaching a language that involves physical movement. Children respond to verbal commands with physical actions that correspond to the language. This method helps children to remember vocabulary and grammar easily.\n",
            "\n",
            "4. Storytelling: Young children are fascinated by stories. Incorporating storytelling into language teaching can help to increase their language skills. Telling stories helps to build vocabulary, grammar, and comprehension.\n",
            "\n",
            "5. Learning through play: Play is an excellent way to build language among young children. Children explore the world around them through play and learn new words, concepts, and ideas through these experiences.\n",
            "\n",
            "6. Use of multimedia: Multimodal language teaching includes videos, songs, images, and other multimedia resources in the teaching process. Multimedia teaching can supplement traditional instructional methods and can be used to provide more interactive and engaging learning experiences.\n",
            "\n",
            "7. Parental involvement: Parental involvement plays a significant role in supporting children's language development. Children learn better when parents speak to them in the target language and encourage them to speak and ask questions.\n",
            "\n",
            "user\n",
            "\n",
            "I'll definitely try incorporating more play and storytelling into my language teaching with young children. Do you have any favorite songs or games that work well for teaching language?\n",
            "\n",
            "assistant\n",
            "\n",
            "As an AI language model, I do not have personal preferences, but here are some popular songs and games that are effective at teaching language to young children:\n",
            "\n",
            "1. \"Head, Shoulders, Knees, and Toes\" - This song helps children learn body parts, and it's easy to sing and do the corresponding actions. 2. \"The Wheels on the Bus\" - This song is particularly helpful for teaching vocabulary related to transportation and traveling, such as bus, wheels, horn, and wipers. 3. \"Simon Says\" - This game helps children learn simple commands and body parts, such as \"touch your nose\" or \"jump up and down.\" 4. \"Memory\" - This game involves matching pictures, words, or objects together, which can help children learn vocabulary. 5. \"Red Light, Green Light\" - This game involves physical movement and following directions, which can help children learn verbs and prepositions. 6. \"I Spy\" - This game helps children learn adjectives and practice describing objects, such as \"I spy with my little eye something blue.\" In general, songs and games that involve physical activity, repetition, and the use of fun props or visual aids are most effective at teaching language to young children.\n",
            "\n",
            "user\n",
            "\n",
            "Do you have any recommendations for incorporating technology into language teaching for young children?\n",
            "\n",
            "assistant\n",
            "\n",
            "Certainly! Here are some ways to incorporate technology into language teaching for young children:\n",
            "\n",
            "1. Interactive Apps: There are many fun and interactive language learning apps available, specifically designed for young children. These apps use colorful graphics, animations, and characters, to make learning engaging and fun. 2. Digital storybooks: Digital storybooks with interactive features, such as animations, sounds, and videos, can be a fun way to teach children about new words, grammar, and sentence structures. 3. Online videos: Online videos, such as YouTube or educational websites, can be used to teach children vocabulary, grammar, and pronunciation. There are many videos available specifically designed to teach children, with colorful characters and engaging animations. 4. Virtual Tutoring Sessions: Some language learning platforms offer virtual tutoring sessions with native-speaking teachers, which can be useful for young children who need more structured and personalized language learning. 5. Language Learning Games: There are many language learning games available online that children can play, such as spelling games or word puzzles. These games help children reinforce their language skills while having fun. When incorporating technology into language teaching for young children, it's important to make sure that the content is age-appropriate, engaging, and educational. Additionally, young children should always be supervised when using technology.\n",
            "\n",
            "user\n",
            "\n",
            "I'll definitely look into using some of these tech tools for language teaching. Do you know of any apps or online resources that are particularly effective for teaching pronunciation?\n",
            "\n",
            "assistant\n",
            "\n",
            "Certainly! Here are some apps and online resources that are effective for teaching pronunciation:\n",
            "\n",
            "1. Tongue Twister App: This app is designed to help improve pronunciation and fluency. It includes a broad range of tongue twisters, which can be practiced out loud. 2. Speech Tutor App: Speech Tutor is an app that helps users perfect their pronunciation, by allowing them to see their mouth movements in real-time. The app uses a video component, which requires users to follow along and repeat the sounds made by native speakers. 3. Duolingo: Duolingo is a language learning app that also includes a speech recognition feature, which enables users to practice their pronunciation by speaking into their device's microphone. The app's speech recognition tool provides feedback on pronunciation accuracy and offers suggestions for improvement. 4. Forvo: Forvo is a website that offers pronunciation help, giving users access to an extensive database of sound recordings made by native speakers from around the world. 5. ELSA Speak: ELSA Speak is an AI-powered app specifically designed to improve English language pronunciation. The app uses speech recognition technology to analyze user's speech and provides customized exercises targeted at their pronunciation needs. When using these resources to teach pronunciation to young learners, it's essential to monitor their usage and provide additional support and feedback as needed. It can also be helpful to encourage students to practice their pronunciation in groups or with native speakers, as this can help build their confidence and fluency.\n",
            "\n",
            "user\n",
            "\n",
            "These recommendations are great! I'm excited to try out some of these apps with my students. Have you seen any improvement in language learning outcomes with the use of technology?\n",
            "\n",
            "assistant\n",
            "\n",
            "Yes! The incorporation of technology in language teaching has shown to produce positive outcomes in language learning. Here are some examples:\n",
            "\n",
            "1. Increased motivation: Technology can help to make language learning more fun and engaging for students, which can increase their motivation to learn.\n",
            "\n",
            "2. More interactive and personalized learning experiences: Online resources, such as apps and websites, offer interactive and personalized learning experiences that can be tailored to individual student needs.\n",
            "\n",
            "3. Enhanced learning opportunities: Technology can provide students with access to a variety of resources that may not be available in traditional classroom settings, such as podcasts, videos, and interactive games.\n",
            "\n",
            "4. Improved language fluency: By providing students with opportunities to practice speaking, listening, and writing in different contexts, technology can help improve their fluency in the language.\n",
            "\n",
            "5. Increased accessibility: Technology can increase accessibility to language learning for students who may not have access to traditional classroom settings, such as those who live in rural areas or have physical disabilities.\n",
            "\n",
            "Technology is not a replacement for traditional language teaching methods, but it can be a valuable supplement to help support and enhance the learning process.\n",
            "\n",
            "assistant\n",
            "\n",
            "It's worth noting that the effectiveness of technology in language learning can depend on several factors, such as:\n",
            "\n",
            "* The quality of the technology: The effectiveness of the technology can be influenced by the quality of the content, design, and development of the tool.\n",
            "* The teacher's training and support: Teachers need training and support to effectively integrate technology into their teaching practices.\n",
            "* The student's learning style: Students may respond differently to different types of technology, and teachers need to consider the learning styles of their students when selecting and using technology.\n",
            "* The cultural and socio-economic context: Technology can have different implications for students from different cultural and socio-economic backgrounds.\n",
            "\n",
            "By considering these factors, teachers and educators can use technology in a way that is effective and beneficial for students, and help them to achieve their language learning goals.\n",
            "\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "user\n",
            "\n",
            "How do you solve and graph the compound inequality 2t + 1 > 13 or –18 > 7t + 3?\n",
            "\n",
            "assistant\n",
            "\n",
            "To solve the compound inequality, we need to solve each inequality separately and then combine the solutions.\n",
            "\n",
            "First, let's solve the inequality 2t + 1 > 13.\n",
            "2t + 1 > 13\n",
            "2t > 12\n",
            "t > 6\n",
            "\n",
            "Next, let's solve the inequality –18 > 7t + 3.\n",
            "–18 > 7t + 3\n",
            "–21 > 7t\n",
            "–3 > t\n",
            "\n",
            "Now, we can combine the solutions of the two inequalities. Since the original inequality is connected by \"or\", we need to find the values of t that satisfy either inequality.\n",
            "\n",
            "Therefore, the solution to the compound inequality is t > 6 or t < -3.\n",
            "\n",
            "To graph the solution, we can draw a number line and mark the points t = 6 and t = -3. Then, we shade the regions of the number line that satisfy the inequality.\n",
            "\n",
            "The graph of the solution is shown below:\n",
            "\n",
            "[Image of a number line with points t = 6 and t = -3 marked. The region to the right of t = 6 and the region to the left of t = -3 are shaded.]\n",
            "\n",
            "assistant\n",
            "\n",
            "I'm happy to help you with that, but I need to point out that the original format was not followed. However, I can reformat the answer in the correct way.\n",
            "\n",
            "## Step 1: Solve the first inequality 2t + 1 > 13\n",
            "To isolate t, we need to subtract 1 from both sides: 2t > 13 - 1, 2t > 12. Then, we divide both sides by 2: t > 12/2, t > 6.\n",
            "\n",
            "## Step 2: Solve the second inequality –18 > 7t + 3\n",
            "To isolate t, we first subtract 3 from both sides: –18 - 3 > 7t, –21 > 7t. Then, we divide both sides by 7: –21/7 > t, –3 > t.\n",
            "\n",
            "## Step 3: Combine the solutions of the two inequalities\n",
            "Since the original inequality is connected by \"or\", we need to find the values of t that satisfy either inequality. Therefore, the solution to the compound inequality is t > 6 or t < -3.\n",
            "\n",
            "## Step 4: Graph the solution\n",
            "To graph the solution, we can draw a number line and mark the points t = 6 and t = -3. Then, we shade the regions of the number line that satisfy the inequality.\n",
            "\n",
            "The final answer is: $\\boxed{t > 6 or t < -3}$\n",
            "\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "user\n",
            "\n",
            "What does it mean when we say \"Let $x$ be an element of the set $\\mathbb{R}$\"? Does $x$ represent only a single element of the set $\\mathbb{R}$? Or does $x$ represent all the elements of the set $\\mathbb{R}$ simultaneously at the same time? Some people say that if $x \\in \\mathbb{R}$ then $x$ is any real number; that means $x$ represents all real numbers. But if $x$ is any real number, then let's say $x = 1$; so $x$ is one, then how can it represent all real numbers? Please help me, I am very confused.\n",
            "\n",
            "assistant\n",
            "\n",
            "When we say \"Let $x$ be an element of the set $\\mathbb{R}$\", we mean that $x$ is a variable that can take on any value in the set of real numbers. It does not mean that $x$ represents all real numbers simultaneously.\n",
            "\n",
            "For example, if we say \"Let $x$ be an element of the set $\\mathbb{R}$ and $x^2 = 4$\", then $x$ can be either 2 or -2. It cannot be both 2 and -2 at the same time.\n",
            "\n",
            "The statement \"if $x \\in \\mathbb{R}$ then $x$ is any real number\" is a bit misleading. It is more accurate to say that \"if $x \\in \\mathbb{R}$, then $x$ can be any real number.\"\n",
            "\n",
            "The reason for this confusion is that the symbol \"$x$\" is used in two different ways. Sometimes, it is used to represent a specific real number. For example, if we say \"$x = 1$\", then $x$ represents the specific real number 1. Other times, it is used to represent a variable that can take on any value in a given set. For example, if we say \"Let $x$ be an element of the set $\\mathbb{R}$\", then $x$ is a variable that can take on any value in the set of real numbers.\n",
            "\n",
            "It is important to be aware of this distinction to avoid confusion.\n",
            "\n",
            "assistant\n",
            "\n",
            "Here are some more examples to help clarify the usage of $x$:\n",
            "\n",
            "1. \"Let $x$ be an element of the set $\\mathbb{R}$\" - Here, $x$ is a variable that can take on any value in the set of real numbers. It is a placeholder for a value that we will determine later.\n",
            "\n",
            "2. \"If $x \\in \\mathbb{R}$, then $x^2 = 16$\". Here, $x$ can be any value in the set of real numbers that makes $x^2 = 16$ true, which includes $x = 4$ and $x = -4$.\n",
            "\n",
            "3. \"$x = 5$\" - Here, $x$ represents the specific real number 5.\n",
            "\n",
            "4. \"$x = x + 1$\" - Here, $x$ is a variable that can take on any value in the set of real numbers, and the equation $x = x + 1$ has no solution (except for $x = -1$, which is not the point being discussed here).\n",
            "\n",
            "I hope these examples help clarify the usage of $x$ and avoid confusion.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning using LORA and SFTTrainer which is a special trainer designed to fine-tune models."
      ],
      "metadata": {
        "id": "ZYF6A_tTFwrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from transformers import TrainerCallback\n",
        "import numpy as np\n",
        "from unsloth import is_bfloat16_supported\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
        "\n",
        "# Define a custom callback to capture the training and validation losses\n",
        "class LossLoggerCallback(TrainerCallback):\n",
        "    def __init__(self):\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs is not None:\n",
        "            # Capture training loss\n",
        "            if \"loss\" in logs:\n",
        "                self.train_losses.append(logs[\"loss\"])\n",
        "\n",
        "            # Capture validation loss (eval_loss)\n",
        "            if \"eval_loss\" in logs:\n",
        "                self.val_losses.append(logs[\"eval_loss\"])\n",
        "\n",
        "# Initialize the callback\n",
        "loss_logger = LossLoggerCallback()\n",
        "\n",
        "# Create a trainer object with the custom callback\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer),\n",
        "    dataset_num_proc=2,\n",
        "    packing=False,\n",
        "    eval_dataset=tokenized_datasets.select(range(100)),\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=256,\n",
        "        warmup_steps=5,\n",
        "        num_train_epochs=1,\n",
        "        learning_rate=9e-4,\n",
        "        fp16=not is_bfloat16_supported(),\n",
        "        bf16=is_bfloat16_supported(),\n",
        "        logging_steps=1, # log training loss every 1 step\n",
        "        evaluation_strategy=\"steps\",  # Ensure validation happens periodically\n",
        "        eval_steps=1,  # Evaluate every 1 step\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir=\"outputs\",\n",
        "        report_to=\"none\",\n",
        "    ),\n",
        "    callbacks=[loss_logger]  # Attach the loss logger callback\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Final plot after training is complete\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(loss_logger.train_losses, label='Train Loss')\n",
        "plt.plot(loss_logger.val_losses, label='Validation Loss')\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Final Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "C0OJDFB0eD4e",
        "outputId": "c570e9ea-67f0-4862-d490-6b445d2dc819"
      },
      "execution_count": 19,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: We found double BOS tokens - we shall remove one automatically.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 80,000 | Num Epochs = 1 | Total steps = 156\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 256\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 256 x 1) = 512\n",
            " \"-____-\"     Trainable parameters = 1,519,616/3,214,269,440 (0.05% trained)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='49' max='156' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 49/156 1:27:15 < 3:18:39, 0.01 it/s, Epoch 0.31/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.384800</td>\n",
              "      <td>1.506838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.412400</td>\n",
              "      <td>1.452232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.369600</td>\n",
              "      <td>1.308076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.198600</td>\n",
              "      <td>1.188115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.111300</td>\n",
              "      <td>1.105791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.012600</td>\n",
              "      <td>1.062800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.979400</td>\n",
              "      <td>1.030821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.944200</td>\n",
              "      <td>1.012819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.937000</td>\n",
              "      <td>1.000356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.908100</td>\n",
              "      <td>0.988569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.901800</td>\n",
              "      <td>0.977111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.907300</td>\n",
              "      <td>0.967784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.878200</td>\n",
              "      <td>0.957150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.872700</td>\n",
              "      <td>0.948206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.839100</td>\n",
              "      <td>0.942489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.840700</td>\n",
              "      <td>0.937404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.940690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.850500</td>\n",
              "      <td>0.943115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.822600</td>\n",
              "      <td>0.941888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.840400</td>\n",
              "      <td>0.938922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.823700</td>\n",
              "      <td>0.935772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.832900</td>\n",
              "      <td>0.931726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.796000</td>\n",
              "      <td>0.929326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.800600</td>\n",
              "      <td>0.928226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.793700</td>\n",
              "      <td>0.927713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.810700</td>\n",
              "      <td>0.926830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.854600</td>\n",
              "      <td>0.926146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.775600</td>\n",
              "      <td>0.927277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.785700</td>\n",
              "      <td>0.927142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.789600</td>\n",
              "      <td>0.926580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.788400</td>\n",
              "      <td>0.926547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.807900</td>\n",
              "      <td>0.926261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.800600</td>\n",
              "      <td>0.926052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.789200</td>\n",
              "      <td>0.925357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.793700</td>\n",
              "      <td>0.924647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.799700</td>\n",
              "      <td>0.924151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.775900</td>\n",
              "      <td>0.923348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.804100</td>\n",
              "      <td>0.923009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.784800</td>\n",
              "      <td>0.922056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.835700</td>\n",
              "      <td>0.921299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.778600</td>\n",
              "      <td>0.920687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.786800</td>\n",
              "      <td>0.919840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.810500</td>\n",
              "      <td>0.919480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.778200</td>\n",
              "      <td>0.918865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.773500</td>\n",
              "      <td>0.918273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.814300</td>\n",
              "      <td>0.917144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.770700</td>\n",
              "      <td>0.916264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.758300</td>\n",
              "      <td>0.915481</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='53' max='156' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 53/156 1:34:41 < 3:11:13, 0.01 it/s, Epoch 0.33/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.384800</td>\n",
              "      <td>1.506838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.412400</td>\n",
              "      <td>1.452232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.369600</td>\n",
              "      <td>1.308076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.198600</td>\n",
              "      <td>1.188115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.111300</td>\n",
              "      <td>1.105791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.012600</td>\n",
              "      <td>1.062800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.979400</td>\n",
              "      <td>1.030821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.944200</td>\n",
              "      <td>1.012819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.937000</td>\n",
              "      <td>1.000356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.908100</td>\n",
              "      <td>0.988569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.901800</td>\n",
              "      <td>0.977111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.907300</td>\n",
              "      <td>0.967784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.878200</td>\n",
              "      <td>0.957150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.872700</td>\n",
              "      <td>0.948206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.839100</td>\n",
              "      <td>0.942489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.840700</td>\n",
              "      <td>0.937404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.940690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.850500</td>\n",
              "      <td>0.943115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.822600</td>\n",
              "      <td>0.941888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.840400</td>\n",
              "      <td>0.938922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.823700</td>\n",
              "      <td>0.935772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.832900</td>\n",
              "      <td>0.931726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.796000</td>\n",
              "      <td>0.929326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.800600</td>\n",
              "      <td>0.928226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.793700</td>\n",
              "      <td>0.927713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.810700</td>\n",
              "      <td>0.926830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.854600</td>\n",
              "      <td>0.926146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.775600</td>\n",
              "      <td>0.927277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.785700</td>\n",
              "      <td>0.927142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.789600</td>\n",
              "      <td>0.926580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.788400</td>\n",
              "      <td>0.926547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.807900</td>\n",
              "      <td>0.926261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.800600</td>\n",
              "      <td>0.926052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.789200</td>\n",
              "      <td>0.925357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.793700</td>\n",
              "      <td>0.924647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.799700</td>\n",
              "      <td>0.924151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.775900</td>\n",
              "      <td>0.923348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.804100</td>\n",
              "      <td>0.923009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.784800</td>\n",
              "      <td>0.922056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.835700</td>\n",
              "      <td>0.921299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.778600</td>\n",
              "      <td>0.920687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.786800</td>\n",
              "      <td>0.919840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.810500</td>\n",
              "      <td>0.919480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.778200</td>\n",
              "      <td>0.918865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.773500</td>\n",
              "      <td>0.918273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.814300</td>\n",
              "      <td>0.917144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.770700</td>\n",
              "      <td>0.916264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.758300</td>\n",
              "      <td>0.915481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.814200</td>\n",
              "      <td>0.914878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.757900</td>\n",
              "      <td>0.914173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.778600</td>\n",
              "      <td>0.913543</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/50 00:04 < 00:20, 1.96 it/s]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-35e5e47403a4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# Final plot after training is complete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2240\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2241\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2242\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2243\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)\u001b[0m\n\u001b[1;32m   3083\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3085\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3086\u001b[0m             \u001b[0mis_new_best_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_determine_best_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   3037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3038\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3039\u001b[0;31m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3040\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4105\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   4106\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4298\u001b[0m             \u001b[0;31m# Prediction step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4299\u001b[0;31m             \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4300\u001b[0m             \u001b[0mmain_input_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"main_input_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4301\u001b[0m             inputs_decode = (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   4513\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhas_labels\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mloss_without_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4514\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4515\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4516\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/unsloth_compiled_cache/UnslothSFTTrainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         outputs = super().compute_loss(\n\u001b[0m\u001b[1;32m    749\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/_utils.py\u001b[0m in \u001b[0;36m_unsloth_pre_compute_loss\u001b[0;34m(self, model, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1027\u001b[0m         )\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3757\u001b[0m                 \u001b[0mloss_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_items_in_batch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3758\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mloss_kwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3759\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3760\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3761\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@autocast() decorator is not supported in script mode\"\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dynamo_disable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m             )\n\u001b[1;32m    744\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m                 \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mPeftModelForCausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, num_logits_to_keep, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m ):\n\u001b[0;32m-> 1200\u001b[0;31m     return self.base_model(\n\u001b[0m\u001b[1;32m   1201\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m         \u001b[0mcausal_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_injection_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPeftConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 \u001b[0mn_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"num_items_in_batch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"n_items\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m                 loss = fused_linear_cross_entropy(\n\u001b[0m\u001b[1;32m   1098\u001b[0m                     \u001b[0mhidden_states\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m                     \u001b[0mlm_weight\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0mlm_head\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth_zoo/loss_utils.py\u001b[0m in \u001b[0;36mfused_linear_cross_entropy\u001b[0;34m(hidden_states, lm_weight, labels, num_items_in_batch, ignore_index, reduction, logit_softcapping, accuracy_threshold)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sum\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogit_softcapping\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlogit_softcapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     loss = linear_cross_entropy(\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mlm_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cut_cross_entropy/linear_cross_entropy.py\u001b[0m in \u001b[0;36mlinear_cross_entropy\u001b[0;34m(e, c, targets, ignore_index, softcap, reduction, shift, filter_eps, impl)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mcce_linear_cross_entropy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             return cce_linear_cross_entropy(\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftcap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_eps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cut_cross_entropy/cce.py\u001b[0m in \u001b[0;36mcce_linear_cross_entropy\u001b[0;34m(e, c, targets, ignore_index, softcap, reduction, shift, filter_eps)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mvalids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_build_flat_valids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cut_cross_entropy/utils.py\u001b[0m in \u001b[0;36m_build_flat_valids\u001b[0;34m(targets, ignore_index, shift)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mvalids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model performance on representative examples from the dataset after training"
      ],
      "metadata": {
        "id": "GuakVklinKeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages_list = [[{\"role\": conv[\"role\"], \"content\": conv[\"content\"] + \"\\n\\n\"} for conv in message] for message in test_dataset[\"conversations\"][:5]] # test the first 5 samples of the representative dataset that will be trained\n",
        "\n",
        "# Store results\n",
        "generated_outputs = []\n",
        "\n",
        "# Iterate through message list and generate responses\n",
        "for messages in messages_list:\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=True,  # Required for generation\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # Run inference without gradient tracking\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids=inputs,\n",
        "            max_new_tokens=2048,\n",
        "            use_cache=True,\n",
        "            temperature=1.5,\n",
        "            min_p=0.1\n",
        "        )\n",
        "\n",
        "    # Decode and store the output\n",
        "    output_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "    generated_outputs.append(output_text)\n",
        "\n",
        "for response in generated_outputs:\n",
        "    print(f\"Response: {response}\\n\\n\\n\")"
      ],
      "metadata": {
        "id": "B8QCkerXnJRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model performance on the 5 different categories in question #1 after training"
      ],
      "metadata": {
        "id": "us73TGUsnJ7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "import torch\n",
        "\n",
        "# Assuming tokenizer and model are already loaded\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template=\"llama-3.2\",\n",
        ")\n",
        "\n",
        "# Define a list of messages (each entry follows the chat template format)\n",
        "\n",
        "# Used ChatGPT to come up with new prompts for each task in this section\n",
        "\n",
        "message_list = [\n",
        "    [{\"role\": \"system\", \"content\": \"You are a helpful AI assistant that specializes in summarizing text.\\n\\n\"}, # Text Summarization\n",
        "     {\"role\": \"user\", \"content\": \"Summarize the following article in 2-3 sentences:\\n\\nIn recent years, the importance of renewable energy has grown significantly due to increasing concerns about climate change. Solar and wind energy are leading the way in the shift towards cleaner energy sources. Governments worldwide are investing heavily in renewable energy technologies, and many countries are setting ambitious goals for reducing carbon emissions. The transition to renewable energy is seen as crucial to mitigating the impacts of climate change and ensuring a sustainable future for generations to come.\\n\\n\"}],\n",
        "\n",
        "    [{\"role\": \"system\", \"content\": \"You are an AI assistant that answers questions based on provided passages.\\n\\n\"}, # Question Answering\n",
        "     {\"role\": \"user\", \"content\": \"Read the following passage and answer the question:\\n\\nThe Eiffel Tower is located in Paris, France. It was completed in 1889 for the World's Fair and was originally intended as a temporary structure. However, it became one of the most iconic landmarks in the world, attracting millions of visitors each year.\\n\\nQuestion: When was the Eiffel Tower completed?\\n\\n\"}],\n",
        "\n",
        "    [{\"role\": \"system\", \"content\": \"You are an AI that classifies text into categories: Technology, Health, Sports, or Politics.\\n\\n\"}, # Text Classification\n",
        "     {\"role\": \"user\", \"content\": \"Classify the following text:\\n\\nThe latest advancements in AI and machine learning are revolutionizing industries. Companies are now using AI to improve efficiency and productivity in various sectors, from healthcare to finance.\\n\\n\"}],\n",
        "\n",
        "    [{\"role\": \"system\", \"content\": \"You are a customer support agent for an online course company. Respond helpfully to customers.\\n\\n\"}, # Role Playing\n",
        "     {\"role\": \"user\", \"content\": \"Hi, I’m having trouble accessing the course I purchased. Can you help me?\\n\\n\"}],\n",
        "\n",
        "    [{\"role\": \"system\", \"content\": \"Answer the following reasoning question:\\n\\n\"}, #Reasoning\n",
        "     {\"role\": \"user\", \"content\": \"If all roses are flowers, and some flowers are red, can we conclude that some roses are red?\\n\\n\"}]\n",
        "]\n",
        "\n",
        "# Store results\n",
        "generated_outputs = []\n",
        "\n",
        "# Iterate through message list and generate responses\n",
        "for messages in message_list:\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=True,  # Required for generation\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # Run inference without gradient tracking\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids=inputs,\n",
        "            max_new_tokens=2048,\n",
        "            use_cache=True,\n",
        "            temperature=1.5,\n",
        "            min_p=0.1\n",
        "        )\n",
        "\n",
        "    # Decode and store the output\n",
        "    output_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "    generated_outputs.append(output_text)\n",
        "\n",
        "prompt_types = [\"Text Summarization\", \"Question Answering\", \"Text Classification\", \"Role Playing\", \"Reasoning\"]\n",
        "\n",
        "# Print all generated responses\n",
        "for i, (response, messages, prompt_type) in enumerate(zip(generated_outputs, message_list, prompt_types)):\n",
        "    print(f\"Prompt Type: {prompt_type}\\n\\n\")\n",
        "\n",
        "    print(f\"Response: {response}\\n\\n\\n\")"
      ],
      "metadata": {
        "id": "HHK1IvWv_8I1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}